{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42a83e9-06b1-4941-bc4f-b477a04fd946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n",
      "Translation of 'hello': হ্যালো\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Translation of 'i love you': আমি তোমায় ভালোবাসি\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1. Sample data\n",
    "eng_sentences = [ 'hello', 'how are you', 'i love you', 'what is your name', 'good morning', \n",
    "                 'where are you going', 'i am hungry', 'can you help me', \n",
    "                 'i am learning bengali', 'thank you very much', \n",
    "                 'do you speak english', 'i do not understand', 'what time is it', \n",
    "                 'where do you live', 'this is my friend', \n",
    "                 'i am feeling sick', 'please come here', 'i will call you later',\n",
    "                 'happy birthday to you', 'have a nice day' ]\n",
    "\n",
    "ben_sentences = [ 'হ্যালো', 'তুমি কেমন আছো', 'আমি তোমায় ভালোবাসি', 'তোমার নাম কি', \n",
    "                 'শুভ সকাল', 'তুমি কোথায় যাচ্ছো', 'আমি ক্ষুধার্ত',\n",
    "                 'তুমি কি আমাকে সাহায্য করতে পারো', 'আমি বাংলা শিখছি', \n",
    "                 'তোমাকে অনেক ধন্যবাদ', 'তুমি কি ইংরেজি বলতে পারো', 'আমি বুঝতে পারছি না', \n",
    "                 'এখন কয়টা বাজে', 'তুমি কোথায় থাকো', \n",
    "                 'এটি আমার বন্ধু', 'আমার অসুস্থ লাগছে', 'অনুগ্রহ করে এখানে আসো', \n",
    "                 'আমি তোমাকে পরে ফোন করবো', 'শুভ জন্মদিন', 'তোমার দিনটা শুভ হোক' ]\n",
    "\n",
    "# 2. Tokenization\n",
    "eng_tokenizer = Tokenizer()\n",
    "ben_tokenizer = Tokenizer(char_level=False)\n",
    "\n",
    "eng_tokenizer.fit_on_texts(eng_sentences)\n",
    "ben_tokenizer.fit_on_texts(ben_sentences)\n",
    "\n",
    "eng_seq = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
    "ben_seq = ben_tokenizer.texts_to_sequences(ben_sentences)\n",
    "\n",
    "# Pad sequences\n",
    "max_len_eng = max(len(seq) for seq in eng_seq)\n",
    "max_len_ben = max(len(seq) for seq in ben_seq)\n",
    "\n",
    "eng_seq = pad_sequences(eng_seq, maxlen=max_len_eng, padding='post')\n",
    "ben_seq = pad_sequences(ben_seq, maxlen=max_len_ben, padding='post')\n",
    "\n",
    "# 3. Define model (very basic seq2seq)\n",
    "vocab_size_eng = len(eng_tokenizer.word_index) + 1\n",
    "vocab_size_ben = len(ben_tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size_eng, 64, input_length=max_len_eng),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.RepeatVector(max_len_ben),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size_ben, activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "ben_seq = np.expand_dims(ben_seq, -1)  # Add extra dimension for sparse loss\n",
    "\n",
    "# 4. Train (very briefly)\n",
    "model.fit(eng_seq, ben_seq, epochs=500, verbose=0)\n",
    "\n",
    "# 5. Translate a new sentence\n",
    "def translate(sentence):\n",
    "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
    "    seq = pad_sequences(seq, maxlen=max_len_eng, padding='post')\n",
    "    pred = model.predict(seq)\n",
    "    pred_seq = np.argmax(pred[0], axis=-1)\n",
    "    words = [word for idx in pred_seq if (word := ben_tokenizer.index_word.get(idx))]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Test\n",
    "print(\"Translation of 'hello':\", translate('hello'))\n",
    "print(\"Translation of 'i love you':\", translate('i love you'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73091430-c6b6-491f-a0f0-c9397b8fc5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
